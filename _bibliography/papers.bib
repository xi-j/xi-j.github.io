---
---

@article{shimizu2025meanflow,
  title={MeanFlow-TSE: One-Step Generative Target Speaker Extraction with Mean Flow},
  author={Shimizu, Riki and Jiang, Xilin and Mesgarani, Nima},
  journal={arXiv preprint arXiv:2512.18572},
  year={2025}
}

@article{dindar2025speaker,
  title={Speaker Identity is Robustly Encoded in Spatial Patterns of Intracranial EEG for Attention Decoding},
  author={Dindar, Sukru Samet and Jiang, Xilin and Choudhari, Vishal and Bickel, Stephan and Mehta, Ashesh and Schevon, Catherine and McKhann, Guy M and Friedman, Daniel and Flinker, Adeen and Mesgarani, Nima},
  journal={bioRxiv},
  pages={2025--12},
  year={2025},
  publisher={Cold Spring Harbor Laboratory}
}

@article{jiang2025sci,
  title={Sci-Phi: A Large Language Model Spatial Audio Descriptor},
  author={Jiang, Xilin and Gamper, Hannes and Braun, Sebastian},
  journal={arXiv preprint arXiv:2510.05542},
  year={2025},
  selected={true}
}

@article{wang2025sightsound,
  title={SightSound-R1: Cross-Modal Reasoning Distillation from Vision to Audio Language Models},
  author={Wang, Qiaolin and Jiang, Xilin and He, Linyang and Wu, Junkai and Mesgarani, Nima},
  journal={arXiv preprint arXiv:2509.15661},
  year={2025}
}

@inproceedings{he2025layer,
  title={Layer-wise minimal pair probing reveals contextual grammatical-conceptual hierarchy in speech representations},
  author={He, Linyang and Wang, Qiaolin and Jiang, Xilin and Mesgarani, Nima},
  booktitle={Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing},
  pages={35326--35341},
  year={2025}
}

@inproceedings{li2026dmospeech,
  title     = {DMOSpeech 2: Reinforcement Learning for Duration Prediction in Metric-Optimized Speech Synthesis},
  author    = {Li, Yinghao Aaron and Jiang, Xilin and Tao, Fei and Niu, Cheng and Xu, Kaifeng and Song, Juntong and Mesgarani, Nima},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)},
  year      = {2026},
  selected={true}
}

@article{Jiang2025BridgingEA,
  title={Bridging Ears and Eyes: Analyzing Audio and Visual Large Language Models to Humans in Visible Sound Recognition and Reducing Their Sensory Gap via Cross-Modal Distillation},
  author={Xilin Jiang and Junkai Wu and Vishal Choudhari and Nima Mesgarani},
  journal={2025 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)},
  year={2025},
  pages={1-5},
  url={https://api.semanticscholar.org/CorpusID:278502230},
  selected={true}
}

@inproceedings{jiang-etal-2025-aad,
    title = "{AAD}-{LLM}: Neural Attention-Driven Auditory Scene Understanding",
    author = "Jiang, Xilin  and
      Dindar, Sukru Samet  and
      Choudhari, Vishal  and
      Bickel, Stephan  and
      Mehta, Ashesh  and
      McKhann, Guy M  and
      Friedman, Daniel  and
      Flinker, Adeen  and
      Mesgarani, Nima",
    editor = "Che, Wanxiang  and
      Nabende, Joyce  and
      Shutova, Ekaterina  and
      Pilehvar, Mohammad Taher",
    booktitle = "Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2025",
    address = "Vienna, Austria",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.acl-long.1257/",
    doi = "10.18653/v1/2025.acl-long.1257",
    pages = "25887--25909",
    ISBN = "979-8-89176-251-0",
    selected={true}
}

@inproceedings{xuarraydps,
  title={ArrayDPS: Unsupervised Blind Speech Separation with a Diffusion Prior},
  author={Xu, Zhongweiyang and Fan, Xulin and Wang, Zhong-Qiu and Jiang, Xilin and Choudhury, Romit Roy},
  booktitle={Forty-second International Conference on Machine Learning}
}

@article{florea2025exploring,
  title={Exploring finetuned audio-LLM on heart murmur features},
  author={Florea, Adrian and Jiang, Xilin and Mesgarani, Nima and Jiang, Xiaofan},
  journal={Smart Health},
  pages={100557},
  year={2025},
  publisher={Elsevier}
}


@INPROCEEDINGS{10889391,
  author={Jiang, Xilin and Li, Yinghao Aaron and Nicolas Florea, Adrian and Han, Cong and Mesgarani, Nima},
  booktitle={ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Speech Slytherin: Examining the Performance and Efficiency of Mamba for Speech Separation, Recognition, and Synthesis}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  keywords={Codes;Speech coding;Memory management;Speech recognition;Transformers;Data models;Acoustics;Speech synthesis;Signal resolution;State space model;speech separation;automatic speech recognition;text-to-speech synthesis},
  doi={10.1109/ICASSP49660.2025.10889391}
  selected={true}  
}

@inproceedings{li-etal-2025-styletts,
    title = "{S}tyle{TTS}-{ZS}: Efficient High-Quality Zero-Shot Text-to-Speech Synthesis with Distilled Time-Varying Style Diffusion",
    author = "Li, Yinghao Aaron  and
      Jiang, Xilin  and
      Han, Cong  and
      Mesgarani, Nima",
    editor = "Chiruzzo, Luis  and
      Ritter, Alan  and
      Wang, Lu",
    booktitle = "Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)",
    month = apr,
    year = "2025",
    address = "Albuquerque, New Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.naacl-long.242/",
    doi = "10.18653/v1/2025.naacl-long.242",
    pages = "4725--4744",
    ISBN = "979-8-89176-189-6",
    abstract = "The rapid development of large-scale text-to-speech (TTS) models has led to significant advancements in modeling diverse speaker prosody and voices. However, these models often face issues such as slow inference speeds, reliance on complex pre-trained neural codec representations, and difficulties in achieving naturalness and high similarity to reference speakers. To address these challenges, this work introduces StyleTTS-ZS, an efficient zero-shot TTS model that leverages distilled time-varying style diffusion to capture diverse speaker identities and prosodies. We propose a novel approach that represents human speech using input text and fixed-length time-varying discrete style codes to capture diverse prosodic variations, trained adversarially with multi-modal discriminators. A diffusion model is then built to sample this time-varying style code for efficient latent diffusion. Using classifier-free guidance, StyleTTS-ZS achieves high similarity to the reference speaker in the style diffusion process. Furthermore, to expedite sampling, the style diffusion model is distilled with perceptual loss using only 10k samples, maintaining speech quality and similarity while reducing inference speed by 90{\%}. Our model surpasses previous state-of-the-art large-scale zero-shot TTS models in both naturalness and similarity, offering a 10-20{\texttimes} faster sampling speed, making it an attractive alternative for efficient large-scale zero-shot TTS systems. The audio demo, code and models are available at https://styletts-zs.github.io/."
}

@INPROCEEDINGS{10832300,
  author={Wu, Junkai and Fan, Xulin and Lu, Bo-Ru and Jiang, Xilin and Mesgarani, Nima and Hasegawa-Johnson, Mark and Ostendorf, Mari},
  booktitle={2024 IEEE Spoken Language Technology Workshop (SLT)}, 
  title={Just ASR + LLM? A Study on Speech Large Language Modelsâ€™ Ability to Identify And Understand Speaker in Spoken Dialogue}, 
  year={2024},
  volume={},
  number={},
  pages={1137-1143},
  keywords={Training;Accuracy;Large language models;Conferences;Oral communication;Benchmark testing;Cognition;Question answering (information retrieval);Reliability;Context modeling;speech large language models;spoken question answering;spoken dialogue understanding},
  doi={10.1109/SLT61566.2024.10832300}}

@INPROCEEDINGS{10832304,
  author={Shams, Siavash and Dindar, Sukru Samet and Jiang, Xilin and Mesgarani, Nima},
  booktitle={2024 IEEE Spoken Language Technology Workshop (SLT)}, 
  title={SSAMBA: Self-Supervised Audio Representation Learning With Mamba State Space Model}, 
  year={2024},
  volume={},
  number={},
  pages={1053-1059},
  keywords={Representation learning;Performance evaluation;Technological innovation;Emotion recognition;Computational modeling;Scalability;Memory management;Transformers;Complexity theory;Spectrogram;Audio classification;audio representation learning;state space models;self-supervised learning;deep learning},
  doi={10.1109/SLT61566.2024.10832304}}


@inproceedings{listyletalker,
  title={StyleTalker: Finetuning Audio Language Model and Style-Based Text-to-Speech Model for Fast Spoken Dialogue Generation},
  author={Li, Yinghao Aaron and Jiang, Xilin and Darefsky, Jordan and Zhu, Ge and Mesgarani, Nima},
  booktitle={First Conference on Language Modeling},
  selected={true}
}

@INPROCEEDINGS{10888514,
  author={Jiang, Xilin and Han, Cong and Mesgarani, Nima},
  booktitle={ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Dual-path Mamba: Short and Long-term Bidirectional Selective Structured State Space Models for Speech Separation}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  keywords={Codes;Speech coding;Computational modeling;Computer architecture;Signal processing;Transformers;Data models;Acoustics;Complexity theory;Speech processing;Speech separation;source separation;speech sequence modeling;state space model;deep learning},
  doi={10.1109/ICASSP49660.2025.10888514}
  selected={true}  
}

@article{jiang2025listen,
  title={Listen, Chat, and Remix: Text-Guided Soundscape Remixing for Enhanced Auditory Experience},
  author={Jiang, Xilin and Han, Cong and Li, Yinghao Aaron and Mesgarani, Nima},
  journal={IEEE Journal of Selected Topics in Signal Processing},
  year={2025},
  publisher={IEEE},
  selected={true}
}

@inproceedings{jiang2024exploring,
  title={Exploring self-supervised contrastive learning of spatial sound event representation},
  author={Jiang, Xilin and Han, Cong and Li, Yinghao Aaron and Mesgarani, Nima},
  booktitle={ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={1281--1285},
  year={2024},
  organization={IEEE},
  selected={true}
}

@article{li2023hiftnet,
  title={Hiftnet: A fast high-quality neural vocoder with harmonic-plus-noise filter and inverse short time fourier transform},
  author={Li, Yinghao Aaron and Han, Cong and Jiang, Xilin and Mesgarani, Nima},
  journal={arXiv preprint arXiv:2309.09493},
  year={2023}
}

@inproceedings{li2023phoneme,
  title={Phoneme-level bert for enhanced prosody of text-to-speech with grapheme predictions},
  author={Li, Yinghao Aaron and Han, Cong and Jiang, Xilin and Mesgarani, Nima},
  booktitle={ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={1--5},
  year={2023},
  organization={IEEE}
}

@inproceedings{jiang2023decor,
  title={DeCoR: Defy Knowledge Forgetting by Predicting Earlier Audio Codes},
  author={Jiang, Xilin and Li, Yinghao Aaron and Mesgarani, Nima},
  booktitle={Proc. Interspeech 2023},
  pages={2818--2822},
  year={2023}
}

@article{sayed2025continual,
  title={Continual learning for energy management systems: A review of methods and applications, and a case study},
  author={Sayed, Aya Nabil and Himeur, Yassine and Varlamis, Iraklis and Bensaali, Faycal},
  journal={Applied Energy},
  volume={384},
  pages={125458},
  year={2025},
  publisher={Elsevier}
}

@article{tzinis2022compute,
  title={Compute and memory efficient universal sound source separation},
  author={Tzinis, Efthymios and Wang, Zhepei and Jiang, Xilin and Smaragdis, Paris},
  journal={Journal of Signal Processing Systems},
  volume={94},
  number={2},
  pages={245--259},
  year={2022},
  publisher={Springer}
}